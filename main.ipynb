{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: fancyimpute in /opt/anaconda3/lib/python3.11/site-packages (0.7.0)\n",
      "Requirement already satisfied: knnimpute>=0.1.0 in /opt/anaconda3/lib/python3.11/site-packages (from fancyimpute) (0.1.0)\n",
      "Requirement already satisfied: scikit-learn>=0.24.2 in /opt/anaconda3/lib/python3.11/site-packages (from fancyimpute) (1.2.2)\n",
      "Requirement already satisfied: cvxpy in /opt/anaconda3/lib/python3.11/site-packages (from fancyimpute) (1.5.3)\n",
      "Requirement already satisfied: cvxopt in /opt/anaconda3/lib/python3.11/site-packages (from fancyimpute) (1.3.2)\n",
      "Requirement already satisfied: pytest in /opt/anaconda3/lib/python3.11/site-packages (from fancyimpute) (7.4.0)\n",
      "Requirement already satisfied: nose in /opt/anaconda3/lib/python3.11/site-packages (from fancyimpute) (1.3.7)\n",
      "Requirement already satisfied: six in /opt/anaconda3/lib/python3.11/site-packages (from knnimpute>=0.1.0->fancyimpute) (1.16.0)\n",
      "Requirement already satisfied: numpy>=1.10 in /opt/anaconda3/lib/python3.11/site-packages (from knnimpute>=0.1.0->fancyimpute) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.3.2 in /opt/anaconda3/lib/python3.11/site-packages (from scikit-learn>=0.24.2->fancyimpute) (1.11.4)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /opt/anaconda3/lib/python3.11/site-packages (from scikit-learn>=0.24.2->fancyimpute) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/anaconda3/lib/python3.11/site-packages (from scikit-learn>=0.24.2->fancyimpute) (2.2.0)\n",
      "Requirement already satisfied: iniconfig in /opt/anaconda3/lib/python3.11/site-packages (from pytest->fancyimpute) (1.1.1)\n",
      "Requirement already satisfied: packaging in /opt/anaconda3/lib/python3.11/site-packages (from pytest->fancyimpute) (23.1)\n",
      "Requirement already satisfied: pluggy<2.0,>=0.12 in /opt/anaconda3/lib/python3.11/site-packages (from pytest->fancyimpute) (1.0.0)\n",
      "Requirement already satisfied: streamlit in /opt/anaconda3/lib/python3.11/site-packages (1.39.0)\n",
      "Requirement already satisfied: altair<6,>=4.0 in /opt/anaconda3/lib/python3.11/site-packages (from streamlit) (5.0.1)\n",
      "Requirement already satisfied: blinker<2,>=1.0.0 in /opt/anaconda3/lib/python3.11/site-packages (from streamlit) (1.6.2)\n",
      "Requirement already satisfied: cachetools<6,>=4.0 in /opt/anaconda3/lib/python3.11/site-packages (from streamlit) (4.2.2)\n",
      "Requirement already satisfied: click<9,>=7.0 in /opt/anaconda3/lib/python3.11/site-packages (from streamlit) (8.1.7)\n",
      "Requirement already satisfied: numpy<3,>=1.20 in /opt/anaconda3/lib/python3.11/site-packages (from streamlit) (1.26.4)\n",
      "Requirement already satisfied: packaging<25,>=20 in /opt/anaconda3/lib/python3.11/site-packages (from streamlit) (23.1)\n",
      "Requirement already satisfied: pandas<3,>=1.4.0 in /opt/anaconda3/lib/python3.11/site-packages (from streamlit) (2.1.4)\n",
      "Requirement already satisfied: pillow<11,>=7.1.0 in /opt/anaconda3/lib/python3.11/site-packages (from streamlit) (10.2.0)\n",
      "Requirement already satisfied: protobuf<6,>=3.20 in /opt/anaconda3/lib/python3.11/site-packages (from streamlit) (3.20.3)\n",
      "Requirement already satisfied: pyarrow>=7.0 in /opt/anaconda3/lib/python3.11/site-packages (from streamlit) (14.0.2)\n",
      "Requirement already satisfied: requests<3,>=2.27 in /opt/anaconda3/lib/python3.11/site-packages (from streamlit) (2.31.0)\n",
      "Requirement already satisfied: rich<14,>=10.14.0 in /opt/anaconda3/lib/python3.11/site-packages (from streamlit) (13.3.5)\n",
      "Requirement already satisfied: tenacity<10,>=8.1.0 in /opt/anaconda3/lib/python3.11/site-packages (from streamlit) (8.2.2)\n",
      "Requirement already satisfied: toml<2,>=0.10.1 in /opt/anaconda3/lib/python3.11/site-packages (from streamlit) (0.10.2)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.3.0 in /opt/anaconda3/lib/python3.11/site-packages (from streamlit) (4.9.0)\n",
      "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /opt/anaconda3/lib/python3.11/site-packages (from streamlit) (3.1.37)\n",
      "Requirement already satisfied: pydeck<1,>=0.8.0b4 in /opt/anaconda3/lib/python3.11/site-packages (from streamlit) (0.8.0)\n",
      "Requirement already satisfied: tornado<7,>=6.0.3 in /opt/anaconda3/lib/python3.11/site-packages (from streamlit) (6.3.3)\n",
      "Requirement already satisfied: jinja2 in /opt/anaconda3/lib/python3.11/site-packages (from altair<6,>=4.0->streamlit) (3.1.3)\n",
      "Requirement already satisfied: jsonschema>=3.0 in /opt/anaconda3/lib/python3.11/site-packages (from altair<6,>=4.0->streamlit) (4.19.2)\n",
      "Requirement already satisfied: toolz in /opt/anaconda3/lib/python3.11/site-packages (from altair<6,>=4.0->streamlit) (0.12.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /opt/anaconda3/lib/python3.11/site-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.7)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/anaconda3/lib/python3.11/site-packages (from pandas<3,>=1.4.0->streamlit) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/lib/python3.11/site-packages (from pandas<3,>=1.4.0->streamlit) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/anaconda3/lib/python3.11/site-packages (from pandas<3,>=1.4.0->streamlit) (2023.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.11/site-packages (from requests<3,>=2.27->streamlit) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.11/site-packages (from requests<3,>=2.27->streamlit) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.11/site-packages (from requests<3,>=2.27->streamlit) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.11/site-packages (from requests<3,>=2.27->streamlit) (2024.8.30)\n",
      "Requirement already satisfied: markdown-it-py<3.0.0,>=2.2.0 in /opt/anaconda3/lib/python3.11/site-packages (from rich<14,>=10.14.0->streamlit) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/anaconda3/lib/python3.11/site-packages (from rich<14,>=10.14.0->streamlit) (2.15.1)\n",
      "Requirement already satisfied: smmap<5,>=3.0.1 in /opt/anaconda3/lib/python3.11/site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/lib/python3.11/site-packages (from jinja2->altair<6,>=4.0->streamlit) (2.1.3)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /opt/anaconda3/lib/python3.11/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (23.1.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /opt/anaconda3/lib/python3.11/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2023.7.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /opt/anaconda3/lib/python3.11/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.30.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /opt/anaconda3/lib/python3.11/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.10.6)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/anaconda3/lib/python3.11/site-packages (from markdown-it-py<3.0.0,>=2.2.0->rich<14,>=10.14.0->streamlit) (0.1.0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.16.0)\n",
      "Requirement already satisfied: joblib==1.4.2 in /opt/anaconda3/lib/python3.11/site-packages (1.4.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install fancyimpute\n",
    "!pip install streamlit\n",
    "!pip install joblib==1.4.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import joblib\n",
    "from scripts.aussie_rain import *\n",
    "from scripts.aussie_rain_process_user_data import *\n",
    "from scripts.train import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import plot_tree, export_text\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 150)\n",
    "sns.set_style('darkgrid')\n",
    "matplotlib.rcParams['font.size'] = 14\n",
    "matplotlib.rcParams['figure.figsize'] = (10, 6)\n",
    "matplotlib.rcParams['figure.facecolor'] = '#00000000'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Завантажую дані в датафрейм"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_df = pd.read_csv('data/weatherAUS.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Location</th>\n",
       "      <th>MinTemp</th>\n",
       "      <th>MaxTemp</th>\n",
       "      <th>Rainfall</th>\n",
       "      <th>Evaporation</th>\n",
       "      <th>Sunshine</th>\n",
       "      <th>WindGustDir</th>\n",
       "      <th>WindGustSpeed</th>\n",
       "      <th>WindDir9am</th>\n",
       "      <th>WindDir3pm</th>\n",
       "      <th>WindSpeed9am</th>\n",
       "      <th>WindSpeed3pm</th>\n",
       "      <th>Humidity9am</th>\n",
       "      <th>Humidity3pm</th>\n",
       "      <th>Pressure9am</th>\n",
       "      <th>Pressure3pm</th>\n",
       "      <th>Cloud9am</th>\n",
       "      <th>Cloud3pm</th>\n",
       "      <th>Temp9am</th>\n",
       "      <th>Temp3pm</th>\n",
       "      <th>RainToday</th>\n",
       "      <th>RainTomorrow</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2008-12-01</td>\n",
       "      <td>Albury</td>\n",
       "      <td>13.4</td>\n",
       "      <td>22.9</td>\n",
       "      <td>0.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>W</td>\n",
       "      <td>44.0</td>\n",
       "      <td>W</td>\n",
       "      <td>WNW</td>\n",
       "      <td>20.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1007.7</td>\n",
       "      <td>1007.1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.9</td>\n",
       "      <td>21.8</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2008-12-02</td>\n",
       "      <td>Albury</td>\n",
       "      <td>7.4</td>\n",
       "      <td>25.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>WNW</td>\n",
       "      <td>44.0</td>\n",
       "      <td>NNW</td>\n",
       "      <td>WSW</td>\n",
       "      <td>4.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1010.6</td>\n",
       "      <td>1007.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.2</td>\n",
       "      <td>24.3</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2008-12-03</td>\n",
       "      <td>Albury</td>\n",
       "      <td>12.9</td>\n",
       "      <td>25.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>WSW</td>\n",
       "      <td>46.0</td>\n",
       "      <td>W</td>\n",
       "      <td>WSW</td>\n",
       "      <td>19.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1007.6</td>\n",
       "      <td>1008.7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>23.2</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2008-12-04</td>\n",
       "      <td>Albury</td>\n",
       "      <td>9.2</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NE</td>\n",
       "      <td>24.0</td>\n",
       "      <td>SE</td>\n",
       "      <td>E</td>\n",
       "      <td>11.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1017.6</td>\n",
       "      <td>1012.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.1</td>\n",
       "      <td>26.5</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2008-12-05</td>\n",
       "      <td>Albury</td>\n",
       "      <td>17.5</td>\n",
       "      <td>32.3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>W</td>\n",
       "      <td>41.0</td>\n",
       "      <td>ENE</td>\n",
       "      <td>NW</td>\n",
       "      <td>7.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>1010.8</td>\n",
       "      <td>1006.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>29.7</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date Location  MinTemp  MaxTemp  Rainfall  Evaporation  Sunshine  \\\n",
       "0  2008-12-01   Albury     13.4     22.9       0.6          NaN       NaN   \n",
       "1  2008-12-02   Albury      7.4     25.1       0.0          NaN       NaN   \n",
       "2  2008-12-03   Albury     12.9     25.7       0.0          NaN       NaN   \n",
       "3  2008-12-04   Albury      9.2     28.0       0.0          NaN       NaN   \n",
       "4  2008-12-05   Albury     17.5     32.3       1.0          NaN       NaN   \n",
       "\n",
       "  WindGustDir  WindGustSpeed WindDir9am WindDir3pm  WindSpeed9am  \\\n",
       "0           W           44.0          W        WNW          20.0   \n",
       "1         WNW           44.0        NNW        WSW           4.0   \n",
       "2         WSW           46.0          W        WSW          19.0   \n",
       "3          NE           24.0         SE          E          11.0   \n",
       "4           W           41.0        ENE         NW           7.0   \n",
       "\n",
       "   WindSpeed3pm  Humidity9am  Humidity3pm  Pressure9am  Pressure3pm  Cloud9am  \\\n",
       "0          24.0         71.0         22.0       1007.7       1007.1       8.0   \n",
       "1          22.0         44.0         25.0       1010.6       1007.8       NaN   \n",
       "2          26.0         38.0         30.0       1007.6       1008.7       NaN   \n",
       "3           9.0         45.0         16.0       1017.6       1012.8       NaN   \n",
       "4          20.0         82.0         33.0       1010.8       1006.0       7.0   \n",
       "\n",
       "   Cloud3pm  Temp9am  Temp3pm RainToday RainTomorrow  \n",
       "0       NaN     16.9     21.8        No           No  \n",
       "1       NaN     17.2     24.3        No           No  \n",
       "2       2.0     21.0     23.2        No           No  \n",
       "3       NaN     18.1     26.5        No           No  \n",
       "4       8.0     17.8     29.7        No           No  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 145460 entries, 0 to 145459\n",
      "Data columns (total 23 columns):\n",
      " #   Column         Non-Null Count   Dtype  \n",
      "---  ------         --------------   -----  \n",
      " 0   Date           145460 non-null  object \n",
      " 1   Location       145460 non-null  object \n",
      " 2   MinTemp        143975 non-null  float64\n",
      " 3   MaxTemp        144199 non-null  float64\n",
      " 4   Rainfall       142199 non-null  float64\n",
      " 5   Evaporation    82670 non-null   float64\n",
      " 6   Sunshine       75625 non-null   float64\n",
      " 7   WindGustDir    135134 non-null  object \n",
      " 8   WindGustSpeed  135197 non-null  float64\n",
      " 9   WindDir9am     134894 non-null  object \n",
      " 10  WindDir3pm     141232 non-null  object \n",
      " 11  WindSpeed9am   143693 non-null  float64\n",
      " 12  WindSpeed3pm   142398 non-null  float64\n",
      " 13  Humidity9am    142806 non-null  float64\n",
      " 14  Humidity3pm    140953 non-null  float64\n",
      " 15  Pressure9am    130395 non-null  float64\n",
      " 16  Pressure3pm    130432 non-null  float64\n",
      " 17  Cloud9am       89572 non-null   float64\n",
      " 18  Cloud3pm       86102 non-null   float64\n",
      " 19  Temp9am        143693 non-null  float64\n",
      " 20  Temp3pm        141851 non-null  float64\n",
      " 21  RainToday      142199 non-null  object \n",
      " 22  RainTomorrow   142193 non-null  object \n",
      "dtypes: float64(16), object(7)\n",
      "memory usage: 25.5+ MB\n"
     ]
    }
   ],
   "source": [
    "raw_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В датасеті є 145460 рядків, так як RainTomorrow є цільовою змінною, то незапонені рядки нам не потрібні для навчання, а отже їх потрібно видалити"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_df.dropna(subset=['RainToday', 'RainTomorrow'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 140787 entries, 0 to 145458\n",
      "Data columns (total 23 columns):\n",
      " #   Column         Non-Null Count   Dtype  \n",
      "---  ------         --------------   -----  \n",
      " 0   Date           140787 non-null  object \n",
      " 1   Location       140787 non-null  object \n",
      " 2   MinTemp        140319 non-null  float64\n",
      " 3   MaxTemp        140480 non-null  float64\n",
      " 4   Rainfall       140787 non-null  float64\n",
      " 5   Evaporation    81093 non-null   float64\n",
      " 6   Sunshine       73982 non-null   float64\n",
      " 7   WindGustDir    131624 non-null  object \n",
      " 8   WindGustSpeed  131682 non-null  float64\n",
      " 9   WindDir9am     131127 non-null  object \n",
      " 10  WindDir3pm     137117 non-null  object \n",
      " 11  WindSpeed9am   139732 non-null  float64\n",
      " 12  WindSpeed3pm   138256 non-null  float64\n",
      " 13  Humidity9am    139270 non-null  float64\n",
      " 14  Humidity3pm    137286 non-null  float64\n",
      " 15  Pressure9am    127044 non-null  float64\n",
      " 16  Pressure3pm    127018 non-null  float64\n",
      " 17  Cloud9am       88162 non-null   float64\n",
      " 18  Cloud3pm       84693 non-null   float64\n",
      " 19  Temp9am        140131 non-null  float64\n",
      " 20  Temp3pm        138163 non-null  float64\n",
      " 21  RainToday      140787 non-null  object \n",
      " 22  RainTomorrow   140787 non-null  object \n",
      "dtypes: float64(16), object(7)\n",
      "memory usage: 25.8+ MB\n"
     ]
    }
   ],
   "source": [
    "raw_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В даному варіанті вирішення задачі колонка дата не є важливою, так як не використовуються часові ряди і взаємозалежності даних в даті, хоча наприклад місяць може мати значення для ймовірності дощу, тому місяць додам новою фічею"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RainTomorrow\n",
       "No     109586\n",
       "Yes     31201\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_df.RainTomorrow.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "bat"
    }
   },
   "source": [
    "Бачимо незбалансовані класи, а для навчання дерев краще все ж використовувати збалансовані класи"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 140787 entries, 0 to 145458\n",
      "Data columns (total 23 columns):\n",
      " #   Column         Non-Null Count   Dtype  \n",
      "---  ------         --------------   -----  \n",
      " 0   Date           140787 non-null  object \n",
      " 1   Location       140787 non-null  object \n",
      " 2   MinTemp        140319 non-null  float64\n",
      " 3   MaxTemp        140480 non-null  float64\n",
      " 4   Rainfall       140787 non-null  float64\n",
      " 5   Evaporation    81093 non-null   float64\n",
      " 6   Sunshine       73982 non-null   float64\n",
      " 7   WindGustDir    131624 non-null  object \n",
      " 8   WindGustSpeed  131682 non-null  float64\n",
      " 9   WindDir9am     131127 non-null  object \n",
      " 10  WindDir3pm     137117 non-null  object \n",
      " 11  WindSpeed9am   139732 non-null  float64\n",
      " 12  WindSpeed3pm   138256 non-null  float64\n",
      " 13  Humidity9am    139270 non-null  float64\n",
      " 14  Humidity3pm    137286 non-null  float64\n",
      " 15  Pressure9am    127044 non-null  float64\n",
      " 16  Pressure3pm    127018 non-null  float64\n",
      " 17  Cloud9am       88162 non-null   float64\n",
      " 18  Cloud3pm       84693 non-null   float64\n",
      " 19  Temp9am        140131 non-null  float64\n",
      " 20  Temp3pm        138163 non-null  float64\n",
      " 21  RainToday      140787 non-null  object \n",
      " 22  RainTomorrow   140787 non-null  object \n",
      "dtypes: float64(16), object(7)\n",
      "memory usage: 25.8+ MB\n"
     ]
    }
   ],
   "source": [
    "raw_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Робимо препроцессинг - а саме - скейлимо числові колонки, крім значення місяця і показника дощу сьогодні, кодуємо категоріальні колонки, балансуємо класи з допомогою SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/olgamordachova/PycharmProjects/aussie_rain_tree/scripts/aussie_rain.py:75: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_train[categories_encoded_cols] = encoderObj.transform(inputs_train[categorical_cols])\n",
      "/Users/olgamordachova/PycharmProjects/aussie_rain_tree/scripts/aussie_rain.py:75: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_train[categories_encoded_cols] = encoderObj.transform(inputs_train[categorical_cols])\n",
      "/Users/olgamordachova/PycharmProjects/aussie_rain_tree/scripts/aussie_rain.py:75: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_train[categories_encoded_cols] = encoderObj.transform(inputs_train[categorical_cols])\n",
      "/Users/olgamordachova/PycharmProjects/aussie_rain_tree/scripts/aussie_rain.py:75: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_train[categories_encoded_cols] = encoderObj.transform(inputs_train[categorical_cols])\n",
      "/Users/olgamordachova/PycharmProjects/aussie_rain_tree/scripts/aussie_rain.py:75: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_train[categories_encoded_cols] = encoderObj.transform(inputs_train[categorical_cols])\n",
      "/Users/olgamordachova/PycharmProjects/aussie_rain_tree/scripts/aussie_rain.py:75: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_train[categories_encoded_cols] = encoderObj.transform(inputs_train[categorical_cols])\n",
      "/Users/olgamordachova/PycharmProjects/aussie_rain_tree/scripts/aussie_rain.py:75: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_train[categories_encoded_cols] = encoderObj.transform(inputs_train[categorical_cols])\n",
      "/Users/olgamordachova/PycharmProjects/aussie_rain_tree/scripts/aussie_rain.py:75: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_train[categories_encoded_cols] = encoderObj.transform(inputs_train[categorical_cols])\n",
      "/Users/olgamordachova/PycharmProjects/aussie_rain_tree/scripts/aussie_rain.py:75: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_train[categories_encoded_cols] = encoderObj.transform(inputs_train[categorical_cols])\n",
      "/Users/olgamordachova/PycharmProjects/aussie_rain_tree/scripts/aussie_rain.py:75: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_train[categories_encoded_cols] = encoderObj.transform(inputs_train[categorical_cols])\n",
      "/Users/olgamordachova/PycharmProjects/aussie_rain_tree/scripts/aussie_rain.py:75: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_train[categories_encoded_cols] = encoderObj.transform(inputs_train[categorical_cols])\n",
      "/Users/olgamordachova/PycharmProjects/aussie_rain_tree/scripts/aussie_rain.py:75: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_train[categories_encoded_cols] = encoderObj.transform(inputs_train[categorical_cols])\n",
      "/Users/olgamordachova/PycharmProjects/aussie_rain_tree/scripts/aussie_rain.py:75: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_train[categories_encoded_cols] = encoderObj.transform(inputs_train[categorical_cols])\n",
      "/Users/olgamordachova/PycharmProjects/aussie_rain_tree/scripts/aussie_rain.py:75: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_train[categories_encoded_cols] = encoderObj.transform(inputs_train[categorical_cols])\n",
      "/Users/olgamordachova/PycharmProjects/aussie_rain_tree/scripts/aussie_rain.py:75: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_train[categories_encoded_cols] = encoderObj.transform(inputs_train[categorical_cols])\n",
      "/Users/olgamordachova/PycharmProjects/aussie_rain_tree/scripts/aussie_rain.py:75: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_train[categories_encoded_cols] = encoderObj.transform(inputs_train[categorical_cols])\n",
      "/Users/olgamordachova/PycharmProjects/aussie_rain_tree/scripts/aussie_rain.py:75: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_train[categories_encoded_cols] = encoderObj.transform(inputs_train[categorical_cols])\n",
      "/Users/olgamordachova/PycharmProjects/aussie_rain_tree/scripts/aussie_rain.py:75: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_train[categories_encoded_cols] = encoderObj.transform(inputs_train[categorical_cols])\n",
      "/Users/olgamordachova/PycharmProjects/aussie_rain_tree/scripts/aussie_rain.py:75: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_train[categories_encoded_cols] = encoderObj.transform(inputs_train[categorical_cols])\n",
      "/Users/olgamordachova/PycharmProjects/aussie_rain_tree/scripts/aussie_rain.py:76: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_val[categories_encoded_cols] = encoderObj.transform(inputs_val[categorical_cols])\n",
      "/Users/olgamordachova/PycharmProjects/aussie_rain_tree/scripts/aussie_rain.py:76: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_val[categories_encoded_cols] = encoderObj.transform(inputs_val[categorical_cols])\n",
      "/Users/olgamordachova/PycharmProjects/aussie_rain_tree/scripts/aussie_rain.py:76: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_val[categories_encoded_cols] = encoderObj.transform(inputs_val[categorical_cols])\n",
      "/Users/olgamordachova/PycharmProjects/aussie_rain_tree/scripts/aussie_rain.py:76: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_val[categories_encoded_cols] = encoderObj.transform(inputs_val[categorical_cols])\n",
      "/Users/olgamordachova/PycharmProjects/aussie_rain_tree/scripts/aussie_rain.py:76: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_val[categories_encoded_cols] = encoderObj.transform(inputs_val[categorical_cols])\n",
      "/Users/olgamordachova/PycharmProjects/aussie_rain_tree/scripts/aussie_rain.py:76: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_val[categories_encoded_cols] = encoderObj.transform(inputs_val[categorical_cols])\n",
      "/Users/olgamordachova/PycharmProjects/aussie_rain_tree/scripts/aussie_rain.py:76: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_val[categories_encoded_cols] = encoderObj.transform(inputs_val[categorical_cols])\n",
      "/Users/olgamordachova/PycharmProjects/aussie_rain_tree/scripts/aussie_rain.py:76: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_val[categories_encoded_cols] = encoderObj.transform(inputs_val[categorical_cols])\n",
      "/Users/olgamordachova/PycharmProjects/aussie_rain_tree/scripts/aussie_rain.py:76: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_val[categories_encoded_cols] = encoderObj.transform(inputs_val[categorical_cols])\n",
      "/Users/olgamordachova/PycharmProjects/aussie_rain_tree/scripts/aussie_rain.py:76: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_val[categories_encoded_cols] = encoderObj.transform(inputs_val[categorical_cols])\n",
      "/Users/olgamordachova/PycharmProjects/aussie_rain_tree/scripts/aussie_rain.py:76: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_val[categories_encoded_cols] = encoderObj.transform(inputs_val[categorical_cols])\n",
      "/Users/olgamordachova/PycharmProjects/aussie_rain_tree/scripts/aussie_rain.py:76: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_val[categories_encoded_cols] = encoderObj.transform(inputs_val[categorical_cols])\n",
      "/Users/olgamordachova/PycharmProjects/aussie_rain_tree/scripts/aussie_rain.py:76: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_val[categories_encoded_cols] = encoderObj.transform(inputs_val[categorical_cols])\n",
      "/Users/olgamordachova/PycharmProjects/aussie_rain_tree/scripts/aussie_rain.py:76: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_val[categories_encoded_cols] = encoderObj.transform(inputs_val[categorical_cols])\n",
      "/Users/olgamordachova/PycharmProjects/aussie_rain_tree/scripts/aussie_rain.py:76: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_val[categories_encoded_cols] = encoderObj.transform(inputs_val[categorical_cols])\n",
      "/Users/olgamordachova/PycharmProjects/aussie_rain_tree/scripts/aussie_rain.py:76: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_val[categories_encoded_cols] = encoderObj.transform(inputs_val[categorical_cols])\n",
      "/Users/olgamordachova/PycharmProjects/aussie_rain_tree/scripts/aussie_rain.py:76: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_val[categories_encoded_cols] = encoderObj.transform(inputs_val[categorical_cols])\n",
      "/Users/olgamordachova/PycharmProjects/aussie_rain_tree/scripts/aussie_rain.py:76: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_val[categories_encoded_cols] = encoderObj.transform(inputs_val[categorical_cols])\n",
      "/Users/olgamordachova/PycharmProjects/aussie_rain_tree/scripts/aussie_rain.py:76: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_val[categories_encoded_cols] = encoderObj.transform(inputs_val[categorical_cols])\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(175336, 118)\n"
     ]
    }
   ],
   "source": [
    "results = preprocess_data(raw_df, True)\n",
    "print(results['inputs_train'].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Тренуємо модельку"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, train_score, val_score = trainModel(results, max_depth=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train roc_auc_score 0.8178468768535839, \n",
      "Validation roc_auc_score 0.7678654530522859\n"
     ]
    }
   ],
   "source": [
    "print(f'Train roc_auc_score {train_score}, \\nValidation roc_auc_score {val_score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['model/aussie_rain.joblib']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(model, 'model/aussie_rain.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Завантажимо збережену модель і будемо працювати вже з нею"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ccp_alpha': 0.0,\n",
       " 'class_weight': None,\n",
       " 'criterion': 'gini',\n",
       " 'max_depth': 8,\n",
       " 'max_features': None,\n",
       " 'max_leaf_nodes': None,\n",
       " 'min_impurity_decrease': 0.0,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 2,\n",
       " 'min_weight_fraction_leaf': 0.0,\n",
       " 'random_state': 42,\n",
       " 'splitter': 'best'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2 = joblib.load('model/aussie_rain.joblib')\n",
    "model2.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Виберемо, які параметри важливі для передбачень, щоб даьи змогу користувачу їх вводити на формі"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances = pd.DataFrame({\n",
    "    'column':model2.feature_names_in_,\n",
    "    'importance':model2.feature_importances_\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>column</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Humidity3pm</td>\n",
       "      <td>0.514202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Rainfall</td>\n",
       "      <td>0.120384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sunshine</td>\n",
       "      <td>0.104156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Pressure3pm</td>\n",
       "      <td>0.087021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Cloud3pm</td>\n",
       "      <td>0.071325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>WindGustSpeed</td>\n",
       "      <td>0.058399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>month</td>\n",
       "      <td>0.007516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>WindSpeed3pm</td>\n",
       "      <td>0.004383</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           column  importance\n",
       "9     Humidity3pm    0.514202\n",
       "2        Rainfall    0.120384\n",
       "4        Sunshine    0.104156\n",
       "11    Pressure3pm    0.087021\n",
       "13       Cloud3pm    0.071325\n",
       "5   WindGustSpeed    0.058399\n",
       "17          month    0.007516\n",
       "7    WindSpeed3pm    0.004383"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_importances.sort_values('importance', ascending=False).head(8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проведу експеримент - якщо вибрати тільки ці 8 ознак з датафрейму і навчити на них модель - яка буде точність?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "valuable_cols = ['Humidity3pm', 'Rainfall', 'Sunshine', 'Pressure3pm', 'Cloud3pm', 'WindGustSpeed', 'Date', 'WindSpeed3pm', 'RainTomorrow']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Humidity3pm</th>\n",
       "      <th>Rainfall</th>\n",
       "      <th>Sunshine</th>\n",
       "      <th>Pressure3pm</th>\n",
       "      <th>Cloud3pm</th>\n",
       "      <th>WindGustSpeed</th>\n",
       "      <th>Date</th>\n",
       "      <th>WindSpeed3pm</th>\n",
       "      <th>RainTomorrow</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1007.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>44.0</td>\n",
       "      <td>2008-12-01</td>\n",
       "      <td>24.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1007.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>44.0</td>\n",
       "      <td>2008-12-02</td>\n",
       "      <td>22.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1008.7</td>\n",
       "      <td>2.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>2008-12-03</td>\n",
       "      <td>26.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1012.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24.0</td>\n",
       "      <td>2008-12-04</td>\n",
       "      <td>9.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>33.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1006.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>2008-12-05</td>\n",
       "      <td>20.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Humidity3pm  Rainfall  Sunshine  Pressure3pm  Cloud3pm  WindGustSpeed  \\\n",
       "0         22.0       0.6       NaN       1007.1       NaN           44.0   \n",
       "1         25.0       0.0       NaN       1007.8       NaN           44.0   \n",
       "2         30.0       0.0       NaN       1008.7       2.0           46.0   \n",
       "3         16.0       0.0       NaN       1012.8       NaN           24.0   \n",
       "4         33.0       1.0       NaN       1006.0       8.0           41.0   \n",
       "\n",
       "         Date  WindSpeed3pm RainTomorrow  \n",
       "0  2008-12-01          24.0           No  \n",
       "1  2008-12-02          22.0           No  \n",
       "2  2008-12-03          26.0           No  \n",
       "3  2008-12-04           9.0           No  \n",
       "4  2008-12-05          20.0           No  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thin_df = raw_df[valuable_cols]\n",
    "thin_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "data_thin = preprocess_data(thin_df, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_thin, train_score_thin, val_score_thin = trainModel(data_thin, max_leaf_nodes=38)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train roc_auc_score 0.8014383811653055, \n",
      "Validation roc_auc_score 0.7627520759193358\n"
     ]
    }
   ],
   "source": [
    "print(f'Train roc_auc_score {train_score_thin}, \\nValidation roc_auc_score {val_score_thin}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На валілаційних даних трішки менша точність, проте для такої моделі користувачу не доведеться вводити 23 поля даних, що буде зручнішим в даному випадку, тому я використаю цю модель надалі"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['model/aussie_rain_thin.joblib']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(model_thin, 'model/aussie_rain_thin.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Отримання прогнозу на користувацьких даних"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_cols = valuable_cols.copy()\n",
    "user_cols.remove('RainTomorrow')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_data = pd.DataFrame(np.array([[33, 0.6, 1009, 990, 7, 20, '2024-01-01', 17 ]]), columns = user_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['model/add_data.joblib']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add_data = {\n",
    "    'scaler' : data_thin['scalerObj'],\n",
    "    'columns' : user_cols\n",
    "}\n",
    "joblib.dump(add_data, 'model/add_data.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Робимо препроцессинг користувацьких даних"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_data_preprocessed = preprocess_new_data(user_data, data_thin['scalerObj'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Робимо саме передбачення"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.55027933, 0.44972067]])"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_thin.predict_proba(user_data_preprocessed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Humidity3pm</th>\n",
       "      <th>Rainfall</th>\n",
       "      <th>Sunshine</th>\n",
       "      <th>Pressure3pm</th>\n",
       "      <th>Cloud3pm</th>\n",
       "      <th>WindGustSpeed</th>\n",
       "      <th>WindSpeed3pm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>137286.000000</td>\n",
       "      <td>140787.000000</td>\n",
       "      <td>73982.000000</td>\n",
       "      <td>127018.000000</td>\n",
       "      <td>84693.000000</td>\n",
       "      <td>131682.000000</td>\n",
       "      <td>138256.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>51.449288</td>\n",
       "      <td>2.349974</td>\n",
       "      <td>7.630540</td>\n",
       "      <td>1015.257963</td>\n",
       "      <td>4.499250</td>\n",
       "      <td>39.970520</td>\n",
       "      <td>18.631141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>20.807310</td>\n",
       "      <td>8.465173</td>\n",
       "      <td>3.781729</td>\n",
       "      <td>7.035411</td>\n",
       "      <td>2.719752</td>\n",
       "      <td>13.578201</td>\n",
       "      <td>8.798096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>977.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>37.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.900000</td>\n",
       "      <td>1010.400000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>13.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>52.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.500000</td>\n",
       "      <td>1015.200000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>19.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>66.000000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>10.700000</td>\n",
       "      <td>1020.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>24.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>100.000000</td>\n",
       "      <td>371.000000</td>\n",
       "      <td>14.500000</td>\n",
       "      <td>1039.600000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>135.000000</td>\n",
       "      <td>87.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Humidity3pm       Rainfall      Sunshine    Pressure3pm  \\\n",
       "count  137286.000000  140787.000000  73982.000000  127018.000000   \n",
       "mean       51.449288       2.349974      7.630540    1015.257963   \n",
       "std        20.807310       8.465173      3.781729       7.035411   \n",
       "min         0.000000       0.000000      0.000000     977.100000   \n",
       "25%        37.000000       0.000000      4.900000    1010.400000   \n",
       "50%        52.000000       0.000000      8.500000    1015.200000   \n",
       "75%        66.000000       0.800000     10.700000    1020.000000   \n",
       "max       100.000000     371.000000     14.500000    1039.600000   \n",
       "\n",
       "           Cloud3pm  WindGustSpeed   WindSpeed3pm  \n",
       "count  84693.000000  131682.000000  138256.000000  \n",
       "mean       4.499250      39.970520      18.631141  \n",
       "std        2.719752      13.578201       8.798096  \n",
       "min        0.000000       6.000000       0.000000  \n",
       "25%        2.000000      31.000000      13.000000  \n",
       "50%        5.000000      39.000000      19.000000  \n",
       "75%        7.000000      48.000000      24.000000  \n",
       "max        9.000000     135.000000      87.000000  "
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thin_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.4.2'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
